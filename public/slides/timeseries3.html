<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>IM532 3.0 Applied Time Series Forecasting</title>
    <meta charset="utf-8" />
    <meta name="author" content="Thiyanga Talagala" />
    <meta name="date" content="2020-05-05" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/default-fonts.css" rel="stylesheet" />
    <link href="libs/remark-css/duke-blue.css" rel="stylesheet" />
    <link href="libs/remark-css/hygge-duke.css" rel="stylesheet" />
    <link rel="stylesheet" href="libs/cc-fonts.css" type="text/css" />
    <link rel="stylesheet" href="libs/figure-captions.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# IM532 3.0 Applied Time Series Forecasting
## MSc in Industrial Mathematics
### Thiyanga Talagala
### 5 May 2020

---



# Non-Stationary Time Series

**1. Deterministic trend**

`$$Y_t  = f(t) + \epsilon_t$$`


where `\(\epsilon_t \sim iid(0, \sigma^2)\)`, `\(t = 1, 2, ...T\)`

Mean of the process is time dependent, but the variance of the process is constant.

**2. Random walk**

`$$Y_t = Y_{t-1} + \epsilon_t$$`

**3. Random walk with drift**

`$$Y_t = \alpha+  Y_{t-1} + \epsilon_t$$`

**4. Random walk with drift and deterministic trend**

---
# Common trend removal (de-trending) procedures

1. Deterministic trend: Time-trend regression

      The trend can be removed by fitting a deterministic polynomial time trend. The residual series after removing the trend will give us the de-trended series.

1. Stochastic trend: Differencing
 
      The process is also known as a **Difference-stationary process**.



---

# Trend stationary time series

---

# Difference stationary time series

--
      
# Notation: I(d)

Integrated to order `\(d\)`, `\(I(d)\)`:

series can be made stationary by differencing `\(d\)` times.



---

# Difference stationary process: Random walk model (RW)

**Question: ** Show that random walk process is an `\(I(1)\)` process.

---

# Deterministic trend + Stochastic trend: Random walk with drift (RWD)


---

# Summary: RW vs RWD

---

# Variance stabilization

Eg:

- Square root: `\(W_t = \sqrt{Y_t}\)`

- Logarithm: `\(W_t = log({Y_t})\)`

     - This very useful.
     
     - Interpretable: Changes in a log value are **relative (percent) changes on the original sclae**.
     


---

### Monthly Airline Passenger Numbers 1949-1960

.pull-left[

**Without transformations**

![](timeseries3_files/figure-html/unnamed-chunk-1-1.png)&lt;!-- --&gt;

]

.pull-right[

**Square root transformation**

![](timeseries3_files/figure-html/unnamed-chunk-2-1.png)&lt;!-- --&gt;
]
---


### Australian monthly electricity production: Jan 1956 â€“ Aug 1995

.pull-left[

**Without transformations**

![](timeseries3_files/figure-html/unnamed-chunk-3-1.png)&lt;!-- --&gt;

]

.pull-right[

**Logarithm transformation**

![](timeseries3_files/figure-html/unnamed-chunk-4-1.png)&lt;!-- --&gt;
]

---

# Box-Cox transformation

$$
  f(x)=\begin{cases}
    1, &amp; \text{if `\(x&lt;0\)`} \newline
    0, &amp; \text{otherwise}.
  \end{cases}
$$


Different values of `\(\lambda\)` gives you different transformations.

- `\(\lambda=1\)`: No **substantive** transformation

- `\(\lambda = \frac{1}{2}\)`: Square root plus linear transformation

- `\(\lambda=0\)`: Natural logarithm

- `\(\lambda = -1\)`: Inverse plus 1

Balance the seasonal fluctuations and random variation across the series.

---

# Box-Cox transformation: R codes

**BoxCox.lambda: Automatic selection of Box Cox transformation parameter**


```r
forecast::BoxCox.lambda(AirPassengers)
```

```
[1] -0.2947156
```

Some times this value is not sensible.

**BoxCox: Transformation of the input variable using a Box-Cox transformation**

```r
lambda &lt;- forecast::BoxCox.lambda(AirPassengers)
w &lt;- BoxCox(AirPassengers, lambda)
```

You can pass a user-defined value for `lambda`.

**InvBoxCox: Reverse transformation**

```r
InvBox(w)
```

---

## Box-Cox transformation on `AirPassengers`

.pull-left[

**Without transformations**

```r
autoplot(AirPassengers)+ylab("Monthly Airline Passenger Numbers 1949-1960")
```

![](timeseries3_files/figure-html/unnamed-chunk-6-1.png)&lt;!-- --&gt;

]

.pull-right[

**Box-Cox transformation**

```r
lambda &lt;- forecast::BoxCox.lambda(AirPassengers)
*autoplot(BoxCox(AirPassengers, lambda))+
ylab("Monthly Airline Passenger Numbers 1949-1960")
```



![](timeseries3_files/figure-html/unnamed-chunk-7-1.png)&lt;!-- --&gt;
]

What differences do you notice in the scale?
---

## Note: Box-Cox Transformation

- If `\(\lambda = 0\)`? 

    - Behaves like log transformation. 
    
    - Force forecasts to be positive.
--

- If `\(\lambda =1\)`? No transformation is needed.
--

- If some `\(Y_t = 0\)`?, then must have `\(\lambda &gt; 0\)`.
--
- If some `\(Y_t &lt; 0\)`? Use power transformation or adjust the time series **by adding a constant to all values.**

--

- Choose a simple value of `\(\lambda\)`. It makes explanations easier.

--

- Transformation oftem makes little difference to forecasts but has large effects on PI.

---
# Application

`snaive` + applying BoxCox transformation

.pull-left[


```r
fit &lt;- snaive(AirPassengers, lambda = 0)
autoplot(fit)
```

![](timeseries3_files/figure-html/unnamed-chunk-8-1.png)&lt;!-- --&gt;
]

.pull-right[

## Steps: 

âœ… apply Box-Cox transformation.

âœ… fit a model.

âœ… reverse transformation.

]

&lt;!-- R will do the Box-Cox transformation, Fit model, back transformation--&gt;

---

## What differences do you notice?

.pull-left[

![](timeseries3_files/figure-html/unnamed-chunk-9-1.png)&lt;!-- --&gt;
]

.pull-right[

![](timeseries3_files/figure-html/unnamed-chunk-10-1.png)&lt;!-- --&gt;


]

&lt;!--Monotonically increasing variance vs Non-monotonically increasing variance. Any monotonic transformation wouldn't work here. When you apply boxcox transformation it will transform one part and do the opposite for the other part. There are different ways to handle this. What transformation would work for cangas data set. Video:sd1-4 (48) --&gt;

---

## ARMA(p, q) model


`$$Y_t=c+\phi_1Y_{t-1}+...+\phi_p Y_{t-p}+ \theta_1\epsilon_{t-1}+...+\theta_q\epsilon_{t-q}+\epsilon_t$$`

- These are stationary models.

- They are only suitable for **stationary series**.

## ARIMA(p, d, q) model

Differencing --&gt; ARMA

**Step 1: Differencing**

`$$Y'_t = (1-B)^dY_t$$`

**Step 2: ARMA**

`$$Y'_t=c+\phi_1Y'_{t-1}+...+\phi_p Y'_{t-p}+ \theta_1\epsilon_{t-1}+...+\theta_q\epsilon_{t-q}+\epsilon_t$$`

---

# Time series simulation

`$$Y_t = 0.8Y_{t-1}+\epsilon_t$$`


```r
set.seed(2020)
ts.sim &lt;- arima.sim(list(order = c(1,0,0), ar = 0.8), n = 50)
ts.sim
```

```
Time Series:
Start = 1 
End = 50 
Frequency = 1 
 [1]  2.27965683  1.93415746  0.73482131 -0.15584512  0.97066897  3.21190889
 [7]  2.95764558  2.65674413  1.83979702  1.54785233  0.67798326  0.98957498
[13]  1.70016112  0.85506930  0.38305143 -0.41959484 -1.51575290 -0.95952760
[19] -1.13833338 -0.88848714 -0.05074559  0.44819716  0.16976781  0.73717377
[25] -0.08402103  0.40883341  0.44581996  0.47788225  0.19625900 -1.17126398
[31] -1.50393414 -0.62431338  1.40958653  1.37842627 -0.49557405  2.80517251
[37]  3.19937338  2.92814332  3.26543373  2.40682564  2.01842721  1.78300395
[43]  2.22224228  3.42379943  1.02211523  0.49934908 -0.50466071 -1.10772136
[49] -2.66427655 -2.85367641
```

&gt; Use `?arima.sim` to view more examples.

---

# Automated ARIMA algorithm


```r
Arima(ts.sim, order=c(1, 0, 0), include.mean = FALSE)
```

```
Series: ts.sim 
ARIMA(1,0,0) with zero mean 

Coefficients:
         ar1
      0.8410
s.e.  0.0791

sigma^2 estimated as 0.98:  log likelihood=-70.55
AIC=145.1   AICc=145.36   BIC=148.93
```

&lt;!--Not exactly equals to 0.8, due to an estimation error.--&gt;
---



# Interpretation of R output: ARIMA model 

.content-box-yellow[Intercept form]

Using the backshift notation.

`$$(1-\phi_1B-...-\phi_pB^p)Y'_t=c+(1+\theta_1B+...+\theta_qB^q)\epsilon_t$$`

.content-box-yellow[Mean form]

`$$(1-\phi_1B-...-\phi_pB^p)(Y'_t-\mu)=c+(1+\theta_1B+...+\theta_qB^q)\epsilon_t$$`
Where,

 - `\(Y'_t=(1-B)^dY_t\)`
 
 - `\(\mu = E(Y'_t)\)`, when `\(d \neq 0\)`, otherwise `\(\mu = E(Y'_t)\)`.
 
 - `\(c = \mu(1-\phi_1 - ... - \phi_p)\)`
 
 R always return an estimate of `\(\mu\)`. 
 
 
 &lt;!--How constant relate to the mean of the process. These forms are equivalent. When you can relate c to mu. ARMA models are fitted to the stationary data. Hence, we get mean of stationary data. Data can be stationary in two ways, on it's own or by taking the differencing. If differencing is applied, then you get mean of differenced series, otherwise you get mean of original series.--&gt;


---

# Example 1 

**1. Generate data from the model**

**2. Fit an ARIMA model to generated data**

---

# Example 2: Model with a constant

---

# Example 3: Model with a drift


```r
ts.sim2 &lt;- arima.sim(list(order = c(0,1,0)), n = 50)
```


```r
Arima(ts.sim2, order=c(0, 1, 0))
```

```
Series: ts.sim2 
ARIMA(0,1,0) 

sigma^2 estimated as 1.321:  log likelihood=-77.9
AIC=157.8   AICc=157.89   BIC=159.72
```

---

# `Arima` in R

1. When `\(d=0\)`, provides estimate of `\(\mu = E(Y_t)\)`.

2. Default setting is `include.mean=TRUE`. Setting `includemean=FALSE` will force `\(c=\mu=0\)`.

3. When `\(d &gt; 0\)` sets `\(c=\mu=0\)`.

4. When `\(d=1\)` setting `include.drift=TRUE`, estimates `\(\mu\neq0\)` as `drift`.

5. When `\(d&gt;1\)` no constant is allowed.

---
class: duke-orange, center, middle

# Identifying suitable ARIMA models

---

# Modelling steps

1. Plot the data.

--
2. If necessary, transform the data (using a Box-Cox transformation) to stabilise the variance.
--

3. If the data are non-stationary, take first differences of the data until the data are stationary.
--

4. Examine the ACF/PACF to identify a suitable model.
--

5. Try your chosen model(s), and use the AICc to search for a better model.
--

6. Check the residuals from your chosen model by plotting the ACF of the residuals, and doing a portmanteau test of the residuals. If they do not look like white noise, try a modified model.

--
7. Once the residuals look like white noise, calculate forecasts.

Source: Forecasting: Principles and Practice, Rob J Hyndman and George Athanasopoulos

---

# Step 1: Plot data

1. Detect unusual observations in the data

1. Detect non-stationarity by visual inspections of plots

Stationary series:

- has a constant mean value and fluctuates around the mean.

- constant variance.

- no pattern predictable in the long-term.

---

# Step 1: Plot data (cont.)

.pull-left[

```r
autoplot(AirPassengers)
```

![](timeseries3_files/figure-html/unnamed-chunk-15-1.png)&lt;!-- --&gt;
]

.pull-right[

1. Transformations help to stabilize the variance.

1. Differencing helps to stabilize the mean.


.content-box-yellow[

1. Need transformations?

2. Need differencing?

]

]

---

# Step 2: Apply transformations


```r
log.airpassenger &lt;- log(AirPassengers)
#log.airpassenger &lt;- BoxCox(AirPassengers, lambda = 0)
autoplot(log.airpassenger)
```

![](timeseries3_files/figure-html/unnamed-chunk-16-1.png)&lt;!-- --&gt;

---

## Step 3: Take difference series

### Identifying non-stationarity by looking at plots

- Time series plot

- The ACF of stationary data drops to zero relatively quickly.

- The ACF of non-stationary data decreases slowly.

- For non-stationary data, the value of `\(r_t\)` is often large and positive.

--
### Recap: Non-seasonal differencing and seasonal differencing

** Non seasonal first-order differencing:** `\(Y'_t=Y_t - Y_{t-1}\)`

&lt;!--Miss one observation--&gt;

**Non seasonal second-order differencing:** `\(Y''_t=Y'_t - Y'_{t-1}\)`

&lt;!--Miss two observations--&gt;

**Seasonal differencing:** `\(Y_t - Y_{t-m}\)`

&lt;!--To get rid from prominent seasonal components. --&gt;

- For monthly, `\(m=12\)`, for quarterly, `\(m=4\)`.

&lt;!--We will loosefirst 12 observations--&gt;


- Seasonally differenced series will have `\(T-m\)` observations.
&lt;!--Usually we do not consider differencing more than twice. --&gt;

&gt; There are times differencing once is not enough. However, in practice,it is almost never necessary to go beyound second-order differencing.

&lt;!--Even the second-order differencing is very rare.--&gt;

---
# Step 3: Take difference series (cont.)

ðŸ™‹

.content-box-yellow[Seasonal differencing or Non-seasonal differencing?]

&lt;!--Take seasonal differencing first. Seasonal differencing might be enough, you do not need to do further differencing. First order seasonal differencing never removes the seasonal effect.--&gt;

ðŸ™‹

.content-box-yellow[Interpretation of differencing?]

&lt;!--It is important that if the differencing is used, the differences are interpretable. --&gt;

&lt;!--First differences are the change between one observation and the next. Changes of index. Second order differencing is changes of changes.--&gt;

&lt;!--Seasonal differences are the change between one year to the next.--&gt;

&lt;!--But taking lag 3 differences for yearly data, for example, results in a model which cannot be sensible interpreted.--&gt;

&lt;!--It is important that the differencing are interpretable.--&gt;
---

# Step 3: Take difference series (cont.)

.pull-left[


```r
autoplot(log.airpassenger)
```

![](timeseries3_files/figure-html/unnamed-chunk-17-1.png)&lt;!-- --&gt;

]

.pull-right[

```r
ggAcf(log.airpassenger)
```

![](timeseries3_files/figure-html/unnamed-chunk-18-1.png)&lt;!-- --&gt;

]

---
# Step 3: Take difference series (cont.)

## Operations of differencing

.pull-left[


```r
autoplot(log.airpassenger)
```

![](timeseries3_files/figure-html/unnamed-chunk-19-1.png)&lt;!-- --&gt;

]

.pull-right[

```r
library(magrittr) # to load %&gt;%
#autoplot(diff(log.airpassenger,lag=12))
log.airpassenger %&gt;% diff(lag=12)  %&gt;% autoplot()
```

![](timeseries3_files/figure-html/unnamed-chunk-20-1.png)&lt;!-- --&gt;

Does this look stationary?
]

&lt;!--Strongseasonal component is now vanished. Does this look stationary? --&gt;

---
# Step 3: Take difference series (cont.)

.pull-left[

```r
library(magrittr) # to load %&gt;%
#autoplot(diff(log.airpassenger,lag=12))
log.airpassenger %&gt;% diff(lag=12)  %&gt;% autoplot()
```

![](timeseries3_files/figure-html/unnamed-chunk-21-1.png)&lt;!-- --&gt;

]


.pull-right[

```r
log.airpassenger %&gt;% 
  diff(lag=12) %&gt;% 
  ggAcf()
```

![](timeseries3_files/figure-html/unnamed-chunk-22-1.png)&lt;!-- --&gt;

]

---

# Step 3: Take difference series (cont.)

.pull-left[

```r
library(magrittr) # to load %&gt;%
#autoplot(diff(log.airpassenger,lag=12))
log.airpassenger %&gt;% 
  diff(lag=12) %&gt;% 
  diff(lag=1)  %&gt;% 
  autoplot()
```

![](timeseries3_files/figure-html/unnamed-chunk-23-1.png)&lt;!-- --&gt;

&lt;!--Code for second-order differencing: 
log.airpassenger %&gt;% 
  diff(lag=12) %&gt;% 
  diff(lag=1)  %&gt;% 
  diff(lag=1) %&gt;%
  autoplot() --&gt;

]


.pull-right[

```r
log.airpassenger %&gt;% 
  diff(lag=12) %&gt;% 
  diff(lag=1)  %&gt;% 
  ggAcf()
```

![](timeseries3_files/figure-html/unnamed-chunk-24-1.png)&lt;!-- --&gt;

]
---

# Testing for nonstationarity for the presence of unit roots


- Dickey and Fuller (DF) test

- Augmented DF test

- Phillips and Perron (PP) nonparametric test

-  Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test

---

# KPSS test

**H0:** Series is level or trend stationary.

**H1:** Series is not stationary.



```r
library(urca)
diff.sdiff.log.passenger &lt;- log.airpassenger %&gt;% 
  diff(lag=12) %&gt;% 
  diff(lag=1)

diff.sdiff.log.passenger %&gt;%
  ur.kpss() %&gt;%
  summary()
```

```

####################### 
# KPSS Unit Root Test # 
####################### 

Test is of type: mu with 4 lags. 

Value of test-statistic is: 0.0844 

Critical value for a significance level of: 
                10pct  5pct 2.5pct  1pct
critical values 0.347 0.463  0.574 0.739
```

---

# KPSS test 


```r
ur.kpss(log.airpassenger) %&gt;% summary()
```

```

####################### 
# KPSS Unit Root Test # 
####################### 

Test is of type: mu with 4 lags. 

Value of test-statistic is: 2.8287 

Critical value for a significance level of: 
                10pct  5pct 2.5pct  1pct
critical values 0.347 0.463  0.574 0.739
```


```r
sdiff.log.airpassenger &lt;- AirPassengers %&gt;% log() %&gt;% diff(lag=12)
ur.kpss(sdiff.log.airpassenger) %&gt;% summary()
```

```

####################### 
# KPSS Unit Root Test # 
####################### 

Test is of type: mu with 4 lags. 

Value of test-statistic is: 0.3682 

Critical value for a significance level of: 
                10pct  5pct 2.5pct  1pct
critical values 0.347 0.463  0.574 0.739
```

&lt;!--This gives an idea about only non-seasonal differencing--&gt;

---

# How many differences you need to take?

Non-seasonal: Automatically selecting differences.

&lt;!--With this command you do not need to run KPSS test. It will automatically run the test inside and returns you how many times you need to do differencing.--&gt;


```r
ndiffs(log.airpassenger)
```

```
[1] 1
```


```r
ndiffs(sdiff.log.airpassenger)
```

```
[1] 1
```


```r
ndiffs(diff.sdiff.log.passenger)
```

```
[1] 0
```
---
# How many differences you need to take? (cont.)

Seaonal - Automatically selecting differences.

.pull-left[
STL decomposition: `\(Y_t = T_t + S_t + R_t\)`

Strength of seasonality: 

`$$F_s = max \left(0, 1-\frac{Var(R_t)}{Var(S_t + R_t)}\right)$$`


```r
nsdiffs(log.airpassenger)
```

```
[1] 1
```


```r
log.airpassenger %&gt;% diff(lag=1) %&gt;% nsdiffs()
```

```
[1] 1
```


```r
nsdiffs(sdiff.log.airpassenger)
```

```
[1] 0
```
]

.pull-right[

```r
AirPassengers %&gt;% stl(s.window = 12) %&gt;% autoplot()
```

![](timeseries3_files/figure-html/unnamed-chunk-34-1.png)&lt;!-- --&gt;

]
&lt;!--This is for number of seasonal differencing needed.--&gt;

---
# Step 6: Residual diagnostics

## Fitted values: 

`\(\hat{Y}_{t|t-1}\)`: Forecast of `\(Y_t\)` based on observations `\(Y_1,...Y_t\)`.


## Residuals

`$$e_t=Y_t - \hat{Y}_{t|t-1}$$`

### Assumptions of residuals

- `\(\{e_t\}\)` uncorrelated. If they aren't, then information left in residuals that should be used in computing forecasts.

&lt;!--If you see autocorrelations, then you should go back and adjust residuals. In theoretically, If there is information leftover and we can do something better. But it is not the case you will also be able to do with. If can't you can't. Then stop. If you check you know you have done the best as you can.--&gt;

- `\(\{e_t\}\)` have mean zero. If they don't, then forecasts are biased.

&lt;!--If you see autocorrelations, then you should go back and adjust residuals. We want our residuals to be unbiased. If the mean is not zero. Go and adjust the model. Add an intercept. Whatever you want to do.--&gt;

### Useful properties (for prediction intervals)

- `\(\{e_t\}\)` have constant variance.

- `\(\{e_t\}\)` are normally distributed.

&lt;!--If the following assumptions are wrong that doesn't mean your forecasts are incorrect. --&gt;

---

# Step 6: Residual diagnostics


---

# Step 7: Calculate forecasts

---

# Step 8: Evaluate forecast accuracy.

## How well our model is doing for out-of-sample?


&lt;!--So far we have talked about fitted values and residuals.--&gt;

&lt;!--Train data and Test data. We want to know if forecasts doing well for out-of-sample.--&gt;

Forecast error = True value - Observed value

`$$e_{T+h}=Y_{T+h}-\hat{Y}_{T+h|T}$$`

Where,

`\(Y_{T+h}\)`: `\((T+h)^{th}\)` observation, `\(h=1,..., H\)`

`\(\hat{Y}_{T+h|T}\)`: Forecast based on data uo to time `\(T\)`.

- **True** forecast error as the test data is not used in computing `\(\hat{Y}_{T+h|T}\)`.

- Unlike, residuals, forecast errors on the test set involve multi-step forecasts.

- Use forecast error measures to evaluate the models.

&lt;!--Since, true forecast error, no hat involved.--&gt;
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="libs/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
